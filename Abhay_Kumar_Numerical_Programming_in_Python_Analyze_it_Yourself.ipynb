{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "dPtTGMc0feVV"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meabhaykr/Job-Listing-Web-Scraper-with-Python/blob/main/Abhay_Kumar_Numerical_Programming_in_Python_Analyze_it_Yourself.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Job Listing Web Scraper with Python\n",
        "\n"
      ],
      "metadata": {
        "id": "I97cKlNIeHeO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Web Scraping\n",
        "##### **Contribution**    - Individual\n",
        "##### **Name**            - Abhay Kumar\n",
        "##### **Cohort**            - Monaco"
      ],
      "metadata": {
        "id": "6LuGGGwPfHX4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **General Guidelines** : -\n"
      ],
      "metadata": {
        "id": "dPtTGMc0feVV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Problem Statement: Navigating the Data Science Job Landscape**\n",
        "\n",
        "üöÄ Unleash your creativity in crafting a solution that taps into the heartbeat of the data science job market! Envision an ingenious project that seamlessly wields cutting-edge web scraping techniques and illuminating data analysis.\n",
        "\n",
        "üîç Your mission? To engineer a tool that effortlessly gathers job listings from a multitude of online sources, extracting pivotal nuggets such as job descriptions, qualifications, locations, and salaries.\n",
        "\n",
        "üß© However, the true puzzle lies in deciphering this trove of data. Can your solution discern patterns that spotlight the most coveted skills? Are there threads connecting job types to compensation packages? How might it predict shifts in industry demand?\n",
        "\n",
        "üéØ The core objectives of this challenge are as follows:\n",
        "\n",
        "1. Web Scraping Mastery: Forge an adaptable and potent web scraping mechanism. Your creation should adeptly harvest data science job postings from a diverse array of online platforms. Be ready to navigate evolving website structures and process hefty data loads.\n",
        "\n",
        "2. Data Symphony: Skillfully distill vital insights from the harvested job listings. Extract and cleanse critical information like job titles, company names, descriptions, qualifications, salaries, locations, and deadlines. Think data refinement and organization.\n",
        "\n",
        "3. Market Wizardry: Conjure up analytical tools that conjure meaningful revelations from the gathered data. Dive into the abyss of job demand trends, geographic distribution, salary variations tied to experience and location, favored qualifications, and emerging skill demands.\n",
        "\n",
        "4. Visual Magic: Weave a tapestry of visualization magic. Design captivating charts, graphs, and visual representations that paint a crystal-clear picture of the analyzed data. Make these visuals the compass that guides users through job market intricacies.\n",
        "\n",
        "üåê While the web scraping universe is yours to explore, consider these platforms as potential stomping grounds:\n",
        "\n",
        "* LinkedIn Jobs\n",
        "* Indeed\n",
        "* Naukri\n",
        "* Glassdoor\n",
        "* AngelList\n",
        "\n",
        "üéà Your solution should not only decode the data science job realm but also empower professionals, job seekers, and recruiters to harness the dynamic shifts of the industry. The path is open, the challenge beckons ‚Äì are you ready to embark on this exciting journey?\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WC4RKKoko7qr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GitHub Link -**"
      ],
      "metadata": {
        "id": "FNp8Fz6Xf5LN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/meabhaykr/Job-Listing-Web-Scraper-with-Python"
      ],
      "metadata": {
        "id": "uEN3yULPk2wf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Project Summary:**"
      ],
      "metadata": {
        "id": "Gl4ESOtYdIZo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The project involves web scraping job listings from JobInventory.com for a specific search query and location, cleaning and processing the data, and storing it in a CSV file for future use. It utilizes Python, the requests library for making GET requests, BeautifulSoup for parsing HTML content, and regular expressions for data cleaning. The main objectives are to gather job details such as job title, company name, location, and job description. The scraping process is designed to handle multiple pages of job listings, and the resulting data is stored in a structured format for further analysis."
      ],
      "metadata": {
        "id": "cTaGIE05dALQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Explanation:**"
      ],
      "metadata": {
        "id": "yNMYhmrVdiwn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The project begins by defining the search query (\"data scientist\") and the location (\"New York City, NY\"), along with the base URL of JobInventory.com. It sets up empty lists to store the job details, including titles, companies, locations, and descriptions.\n",
        "\n",
        "A loop is used to iterate through multiple pages of job listings, with the maximum number of pages limited to 5 in this example. For each page, the script constructs the URL with the appropriate parameters and sends a GET request to retrieve the HTML content. BeautifulSoup is used to parse the HTML, and job listings are identified using the specified HTML class.\n",
        "\n",
        "The script then iterates through each job listing on the current page, extracting job details like title, company, location, and description. These details are stored in the respective lists.\n",
        "\n",
        "After scraping all the job listings, the project uses regular expressions to clean up the job descriptions by removing extra white spaces and separating the descriptions from the location information.\n",
        "\n",
        "A Pandas DataFrame is created to structure and organize the scraped data, with columns for job title, company, location, and cleaned job description. Finally, the DataFrame is exported to a CSV file named \"job_listings.csv.\""
      ],
      "metadata": {
        "id": "chJ1OebKdf4q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Requirements:\n",
        "Before you start, make sure you have the following libraries installed in your Python environment:\n",
        "\n",
        "1. requests\n",
        "2. BeautifulSoup (bs4)\n",
        "3. pandas\n",
        "\n",
        "### Project Steps:\n",
        "\n",
        "1. Define Search Query and Location:\n",
        "   - Set your desired search query (e.g., \"data scientist\") and location (e.g., \"New York City, NY\").\n",
        "\n",
        "2. Construct the Base URL:\n",
        "   - Define the base URL for JobInventory.com.\n",
        "\n",
        "3. Create Lists to Store Job Details:\n",
        "   - Initialize empty lists for job titles, companies, locations, and descriptions.\n",
        "\n",
        "4. Scrape Job Listings from Multiple Pages:\n",
        "   - We use a loop to scrape job listings from multiple pages, up to a specified limit (e.g., 5 pages).\n",
        "   - We construct the URL for each page by incrementing the \"start\" parameter.\n",
        "   - Send a GET request to the URL and parse the HTML content using BeautifulSoup.\n",
        "   - Find all the job listings on the page and loop through each one.\n",
        "   - Extract job details such as title, company, location, and description and append them to the respective lists.\n",
        "   - If there are no job listings on the current page, we break out of the loop.\n",
        "\n",
        "5. Clean Up Job Descriptions:\n",
        "   - Use regular expressions to clean up job descriptions, removing extra white spaces and other unwanted characters.\n",
        "\n",
        "6. Create a Pandas DataFrame:\n",
        "   - Store the job details in a Pandas DataFrame, with columns for Title, Company, Location, and Description.\n",
        "\n",
        "7. Export to CSV:\n",
        "   - Export the DataFrame to a CSV file for future analysis.\n",
        "\n",
        "This project demonstrates how to scrape job listings from JobInventory.com across multiple pages, extract key information, and save it for further analysis. The skills learned in this project can be applied to various web scraping tasks, enabling you to collect data from websites efficiently and effectively."
      ],
      "metadata": {
        "id": "B6jXJMjUi2D_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "import requests  # To make HTTP requests\n",
        "from bs4 import BeautifulSoup  # To parse HTML content\n",
        "import re  # Regular expressions for text cleaning\n",
        "import pandas as pd  # To work with data in tabular form\n",
        "\n",
        "# Define the search query and location\n",
        "search_query = \"data scientist\"\n",
        "location = \"New York City, NY\"\n",
        "\n",
        "# Construct the base URL for job listings\n",
        "# The website where you'll be scraping job listings\n",
        "base_url = \"http://www.jobinventory.com\"\n",
        "\n",
        "# Define empty lists to store job details\n",
        "titles = []\n",
        "companies = []\n",
        "locations = []\n",
        "descriptions = []\n",
        "\n",
        "# Set the maximum number of pages to scrape\n",
        "max_pages = 5\n",
        "page_num = 1\n",
        "\n",
        "# Loop through pages to scrape job listings\n",
        "while page_num <= max_pages:\n",
        "\n",
        "    # Construct the URL for the current page\n",
        "    url = f\"{base_url}/search?q={search_query}&l={location}&start={page_num}\"\n",
        "\n",
        "    # Send a GET request to the URL to retrieve the HTML content\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Parse the HTML content using BeautifulSoup\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "    # Find all the job listings on the page\n",
        "    job_listings = soup.find_all(\"li\", class_=\"resultBlock\")\n",
        "\n",
        "    # If there are no job listings on the current page, we have reached the end of the results\n",
        "    if not job_listings:\n",
        "        break\n",
        "\n",
        "    # Loop through each job listing and extract the relevant details\n",
        "    for job in job_listings:\n",
        "        title = job.find(\"div\", class_=\"title\").text.strip()\n",
        "        company = job.find(\"span\", class_=\"company\").text.strip()\n",
        "        location = job.find(\"div\", class_=\"state\").text.split(\"\\xa0-\\xa0\")[-1].strip()\n",
        "        description = job.find(\"div\", class_=\"description\").text.strip()\n",
        "\n",
        "        # Append the extracted details to respective lists\n",
        "        titles.append(title)\n",
        "        companies.append(company)\n",
        "        locations.append(location)\n",
        "        descriptions.append(description)\n",
        "\n",
        "    # Increment the page number for the next iteration\n",
        "    page_num += 1\n",
        "\n",
        "# Clean up the job descriptions using regular expressions\n",
        "regex = re.compile(r\"\\s+\")\n",
        "clean_descriptions = [regex.sub(\" \", d).split(\" - \")[1] for d in descriptions]\n",
        "\n",
        "# Create a Pandas DataFrame to store the job details\n",
        "df = pd.DataFrame(\n",
        "    {\n",
        "        \"Job Title\": titles,\n",
        "        \"Company Name\": companies,\n",
        "        \"Location\": locations,\n",
        "        \"Description\": clean_descriptions,\n",
        "    }\n",
        ")\n",
        "\n",
        "# Export the DataFrame to a CSV file\n",
        "df.to_csv(\"job_listings.csv\", index=False)  # Save the job details to a CSV file\n",
        "\n",
        "# Print a message to indicate that scraping is complete\n",
        "print(\"Scraping has been successfully completed. Check out 'job_listings.csv' for the results.\")\n",
        "\n",
        "# Display the first 40 rows of the DataFrame as a sample\n",
        "df.head(40)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Eyepij04WIJq",
        "outputId": "92c78854-71e4-49a6-dcaa-1f03ab5405a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping has been successfully completed. Check out 'job_listings.csv' for the results.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Job Title  \\\n",
              "0                                 Lead Data Scientist   \n",
              "1                                 Lead Data Scientist   \n",
              "2                     Scientist Data Curator - Remote   \n",
              "3                                      Data Scientist   \n",
              "4        Data Scientist & Machine Learning Specialist   \n",
              "5                        Customer Data Scientist- NYC   \n",
              "6                            Principal Data Scientist   \n",
              "7                     Machine learning/Data scientist   \n",
              "8                                Data Scientist - LLM   \n",
              "9                                           Scientist   \n",
              "10         Machine learning/Data scientist candidates   \n",
              "11                                  Data Scientist IV   \n",
              "12  Scientist/Principal Scientist, Drug Product De...   \n",
              "13                              Senior Data Scientist   \n",
              "14  Scientist/Principal Scientist, Drug Product De...   \n",
              "15  Scientist/Principal Scientist, Drug Product De...   \n",
              "16  Scientist/Principal Scientist, Drug Product De...   \n",
              "17                 Data Scientist-(Remote-on W2 only)   \n",
              "18  Scientist/Principal Scientist, Drug Product De...   \n",
              "19  Scientist/Principal Scientist, Drug Product De...   \n",
              "20                                Lead Data Scientist   \n",
              "21                                Lead Data Scientist   \n",
              "22                    Scientist Data Curator - Remote   \n",
              "23                                     Data Scientist   \n",
              "24       Data Scientist & Machine Learning Specialist   \n",
              "25                           Principal Data Scientist   \n",
              "26                       Customer Data Scientist- NYC   \n",
              "27                               Data Scientist - LLM   \n",
              "28                    Machine learning/Data scientist   \n",
              "29                                          Scientist   \n",
              "30                                  Data Scientist IV   \n",
              "31         Machine learning/Data scientist candidates   \n",
              "32  Scientist/Principal Scientist, Drug Product De...   \n",
              "33  Scientist/Principal Scientist, Drug Product De...   \n",
              "34                 Data Scientist-(Remote-on W2 only)   \n",
              "35                              Senior Data Scientist   \n",
              "36  Scientist/Principal Scientist, Drug Product De...   \n",
              "37  Scientist/Principal Scientist, Drug Product De...   \n",
              "38  Scientist/Principal Scientist, Drug Product De...   \n",
              "39  Scientist/Principal Scientist, Drug Product De...   \n",
              "\n",
              "                      Company Name                Location  \\\n",
              "0                             Tiro            New York, NY   \n",
              "1                           Thomas            New York, NY   \n",
              "2           Rancho BioSciences LLC              Newark, NJ   \n",
              "3   Simpson Thacher & Bartlett LLP            New York, NY   \n",
              "4                  Vaco Technology            New York, NY   \n",
              "5                           h2o.ai            New York, NY   \n",
              "6       InVitro Cell Research, LLC              Leonia, NJ   \n",
              "7                   Themesoft Inc.             Hoboken, NJ   \n",
              "8             Spartan Technologies            New York, NY   \n",
              "9         Talent Software Services              Rahway, NJ   \n",
              "10   Delta System & Software, Inc.             Hoboken, NJ   \n",
              "11                Crystal Equation            New York, NY   \n",
              "12            Bristol Myers Squibb       New York City, NY   \n",
              "13               Equation Staffing            New York, NY   \n",
              "14            Bristol Myers Squibb       New York City, NY   \n",
              "15            Bristol Myers Squibb       New York City, NY   \n",
              "16            Bristol Myers Squibb  Financial District, NY   \n",
              "17            Synergy Technologies            New York, NY   \n",
              "18            Bristol Myers Squibb           Chinatown, NY   \n",
              "19            Bristol Myers Squibb    Brooklyn Heights, NY   \n",
              "20                            Tiro            New York, NY   \n",
              "21                          Thomas            New York, NY   \n",
              "22          Rancho BioSciences LLC              Newark, NJ   \n",
              "23  Simpson Thacher & Bartlett LLP            New York, NY   \n",
              "24                 Vaco Technology            New York, NY   \n",
              "25      InVitro Cell Research, LLC              Leonia, NJ   \n",
              "26                          h2o.ai            New York, NY   \n",
              "27            Spartan Technologies            New York, NY   \n",
              "28                  Themesoft Inc.             Hoboken, NJ   \n",
              "29        Talent Software Services              Rahway, NJ   \n",
              "30                Crystal Equation            New York, NY   \n",
              "31   Delta System & Software, Inc.             Hoboken, NJ   \n",
              "32            Bristol Myers Squibb    Brooklyn Heights, NY   \n",
              "33            Bristol Myers Squibb                 Nyc, NY   \n",
              "34            Synergy Technologies            New York, NY   \n",
              "35               Equation Staffing            New York, NY   \n",
              "36            Bristol Myers Squibb       New York City, NY   \n",
              "37            Bristol Myers Squibb       New York City, NY   \n",
              "38            Bristol Myers Squibb       New York City, NY   \n",
              "39            Bristol Myers Squibb  Financial District, NY   \n",
              "\n",
              "                                          Description  \n",
              "0   Lead Data Scientist Enigma is seekingand visua...  \n",
              "1   looking for a Lead Data Scientist to lead and ...  \n",
              "2   work and its quality. * Collaborate frequently...  \n",
              "3   Simpson Thacher's Data Scientist will play a k...  \n",
              "4   Title: Data Scientist & Machine as data modeli...  \n",
              "5   Opportunity Are you a data scientist or machin...  \n",
              "6   Principal Data Scientist with expertise in pre...  \n",
              "7   Machine learning/Data scientist Hoboken, NJdev...  \n",
              "8                       an experienced Data Scientist  \n",
              "9   Services is in search of a Scientist for a con...  \n",
              "10  Position: Machine learning/Data scientist cand...  \n",
              "11  along the way and provide the path for your pr...  \n",
              "12  models by non-statisticians. Trains scientists...  \n",
              "13  B2B. They are looking for a Senior Data Scient...  \n",
              "14  models by non-statisticians. Trains scientists...  \n",
              "15  models by non-statisticians. Trains scientists...  \n",
              "16  models by non-statisticians. Trains scientists...  \n",
              "17  Title: Data Scientist Clientyou and the other ...  \n",
              "18  models by non-statisticians. Trains scientists...  \n",
              "19  models by non-statisticians. Trains scientists...  \n",
              "20  Lead Data Scientist Enigma is seekingand visua...  \n",
              "21  looking for a Lead Data Scientist to lead and ...  \n",
              "22  work and its quality. * Collaborate frequently...  \n",
              "23  Simpson Thacher's Data Scientist will play a k...  \n",
              "24  Title: Data Scientist & Machine as data modeli...  \n",
              "25  Principal Data Scientist with expertise in pre...  \n",
              "26  Opportunity Are you a data scientist or machin...  \n",
              "27                      an experienced Data Scientist  \n",
              "28  Machine learning/Data scientist Hoboken, NJdev...  \n",
              "29  Services is in search of a Scientist for a con...  \n",
              "30  along the way and provide the path for your pr...  \n",
              "31  Position: Machine learning/Data scientist cand...  \n",
              "32  models by non-statisticians. Trains scientists...  \n",
              "33  models by non-statisticians. Trains scientists...  \n",
              "34  Title: Data Scientist Clientyou and the other ...  \n",
              "35  B2B. They are looking for a Senior Data Scient...  \n",
              "36  models by non-statisticians. Trains scientists...  \n",
              "37  models by non-statisticians. Trains scientists...  \n",
              "38  models by non-statisticians. Trains scientists...  \n",
              "39  models by non-statisticians. Trains scientists...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae167331-c43a-4f8d-8212-351e31280446\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Job Title</th>\n",
              "      <th>Company Name</th>\n",
              "      <th>Location</th>\n",
              "      <th>Description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Lead Data Scientist</td>\n",
              "      <td>Tiro</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>Lead Data Scientist Enigma is seekingand visua...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Lead Data Scientist</td>\n",
              "      <td>Thomas</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>looking for a Lead Data Scientist to lead and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Scientist Data Curator - Remote</td>\n",
              "      <td>Rancho BioSciences LLC</td>\n",
              "      <td>Newark, NJ</td>\n",
              "      <td>work and its quality. * Collaborate frequently...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Simpson Thacher &amp; Bartlett LLP</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>Simpson Thacher's Data Scientist will play a k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Data Scientist &amp; Machine Learning Specialist</td>\n",
              "      <td>Vaco Technology</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>Title: Data Scientist &amp; Machine as data modeli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Customer Data Scientist- NYC</td>\n",
              "      <td>h2o.ai</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>Opportunity Are you a data scientist or machin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Principal Data Scientist</td>\n",
              "      <td>InVitro Cell Research, LLC</td>\n",
              "      <td>Leonia, NJ</td>\n",
              "      <td>Principal Data Scientist with expertise in pre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Machine learning/Data scientist</td>\n",
              "      <td>Themesoft Inc.</td>\n",
              "      <td>Hoboken, NJ</td>\n",
              "      <td>Machine learning/Data scientist Hoboken, NJdev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Data Scientist - LLM</td>\n",
              "      <td>Spartan Technologies</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>an experienced Data Scientist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Scientist</td>\n",
              "      <td>Talent Software Services</td>\n",
              "      <td>Rahway, NJ</td>\n",
              "      <td>Services is in search of a Scientist for a con...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Machine learning/Data scientist candidates</td>\n",
              "      <td>Delta System &amp; Software, Inc.</td>\n",
              "      <td>Hoboken, NJ</td>\n",
              "      <td>Position: Machine learning/Data scientist cand...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Data Scientist IV</td>\n",
              "      <td>Crystal Equation</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>along the way and provide the path for your pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Scientist/Principal Scientist, Drug Product De...</td>\n",
              "      <td>Bristol Myers Squibb</td>\n",
              "      <td>New York City, NY</td>\n",
              "      <td>models by non-statisticians. Trains scientists...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Senior Data Scientist</td>\n",
              "      <td>Equation Staffing</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>B2B. They are looking for a Senior Data Scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Scientist/Principal Scientist, Drug Product De...</td>\n",
              "      <td>Bristol Myers Squibb</td>\n",
              "      <td>New York City, NY</td>\n",
              "      <td>models by non-statisticians. Trains scientists...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Scientist/Principal Scientist, Drug Product De...</td>\n",
              "      <td>Bristol Myers Squibb</td>\n",
              "      <td>New York City, NY</td>\n",
              "      <td>models by non-statisticians. Trains scientists...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Scientist/Principal Scientist, Drug Product De...</td>\n",
              "      <td>Bristol Myers Squibb</td>\n",
              "      <td>Financial District, NY</td>\n",
              "      <td>models by non-statisticians. Trains scientists...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Data Scientist-(Remote-on W2 only)</td>\n",
              "      <td>Synergy Technologies</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>Title: Data Scientist Clientyou and the other ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Scientist/Principal Scientist, Drug Product De...</td>\n",
              "      <td>Bristol Myers Squibb</td>\n",
              "      <td>Chinatown, NY</td>\n",
              "      <td>models by non-statisticians. Trains scientists...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Scientist/Principal Scientist, Drug Product De...</td>\n",
              "      <td>Bristol Myers Squibb</td>\n",
              "      <td>Brooklyn Heights, NY</td>\n",
              "      <td>models by non-statisticians. Trains scientists...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Lead Data Scientist</td>\n",
              "      <td>Tiro</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>Lead Data Scientist Enigma is seekingand visua...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Lead Data Scientist</td>\n",
              "      <td>Thomas</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>looking for a Lead Data Scientist to lead and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Scientist Data Curator - Remote</td>\n",
              "      <td>Rancho BioSciences LLC</td>\n",
              "      <td>Newark, NJ</td>\n",
              "      <td>work and its quality. * Collaborate frequently...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Simpson Thacher &amp; Bartlett LLP</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>Simpson Thacher's Data Scientist will play a k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Data Scientist &amp; Machine Learning Specialist</td>\n",
              "      <td>Vaco Technology</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>Title: Data Scientist &amp; Machine as data modeli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Principal Data Scientist</td>\n",
              "      <td>InVitro Cell Research, LLC</td>\n",
              "      <td>Leonia, NJ</td>\n",
              "      <td>Principal Data Scientist with expertise in pre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Customer Data Scientist- NYC</td>\n",
              "      <td>h2o.ai</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>Opportunity Are you a data scientist or machin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Data Scientist - LLM</td>\n",
              "      <td>Spartan Technologies</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>an experienced Data Scientist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Machine learning/Data scientist</td>\n",
              "      <td>Themesoft Inc.</td>\n",
              "      <td>Hoboken, NJ</td>\n",
              "      <td>Machine learning/Data scientist Hoboken, NJdev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Scientist</td>\n",
              "      <td>Talent Software Services</td>\n",
              "      <td>Rahway, NJ</td>\n",
              "      <td>Services is in search of a Scientist for a con...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Data Scientist IV</td>\n",
              "      <td>Crystal Equation</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>along the way and provide the path for your pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Machine learning/Data scientist candidates</td>\n",
              "      <td>Delta System &amp; Software, Inc.</td>\n",
              "      <td>Hoboken, NJ</td>\n",
              "      <td>Position: Machine learning/Data scientist cand...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Scientist/Principal Scientist, Drug Product De...</td>\n",
              "      <td>Bristol Myers Squibb</td>\n",
              "      <td>Brooklyn Heights, NY</td>\n",
              "      <td>models by non-statisticians. Trains scientists...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Scientist/Principal Scientist, Drug Product De...</td>\n",
              "      <td>Bristol Myers Squibb</td>\n",
              "      <td>Nyc, NY</td>\n",
              "      <td>models by non-statisticians. Trains scientists...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Data Scientist-(Remote-on W2 only)</td>\n",
              "      <td>Synergy Technologies</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>Title: Data Scientist Clientyou and the other ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Senior Data Scientist</td>\n",
              "      <td>Equation Staffing</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>B2B. They are looking for a Senior Data Scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Scientist/Principal Scientist, Drug Product De...</td>\n",
              "      <td>Bristol Myers Squibb</td>\n",
              "      <td>New York City, NY</td>\n",
              "      <td>models by non-statisticians. Trains scientists...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Scientist/Principal Scientist, Drug Product De...</td>\n",
              "      <td>Bristol Myers Squibb</td>\n",
              "      <td>New York City, NY</td>\n",
              "      <td>models by non-statisticians. Trains scientists...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Scientist/Principal Scientist, Drug Product De...</td>\n",
              "      <td>Bristol Myers Squibb</td>\n",
              "      <td>New York City, NY</td>\n",
              "      <td>models by non-statisticians. Trains scientists...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Scientist/Principal Scientist, Drug Product De...</td>\n",
              "      <td>Bristol Myers Squibb</td>\n",
              "      <td>Financial District, NY</td>\n",
              "      <td>models by non-statisticians. Trains scientists...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae167331-c43a-4f8d-8212-351e31280446')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ae167331-c43a-4f8d-8212-351e31280446 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ae167331-c43a-4f8d-8212-351e31280446');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-febb871f-7982-4d73-a485-6975f06855e7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-febb871f-7982-4d73-a485-6975f06855e7')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-febb871f-7982-4d73-a485-6975f06855e7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Conclusion:**"
      ],
      "metadata": {
        "id": "YVtUNywGdyCo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In conclusion, this project demonstrates a web scraping process for collecting job listings from JobInventory.com based on a specific search query and location. It provides a practical example of using Python libraries such as requests, BeautifulSoup, and Pandas to automate data extraction and organization.\n",
        "\n",
        "The script is designed to handle multiple pages of job listings, making it a useful tool for aggregating a substantial amount of data for analysis or job search purposes. The use of regular expressions for data cleaning and structuring enhances the quality of the extracted information.\n",
        "\n",
        "By exporting the data to a CSV file, the project ensures that the scraped job listings can be easily stored, shared, and further analyzed. This project serves as a valuable template for similar web scraping tasks and can be customized for different websites and data requirements."
      ],
      "metadata": {
        "id": "USBi_Q6gdvta"
      }
    }
  ]
}